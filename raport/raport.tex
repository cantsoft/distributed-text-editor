% --------------------------------------------------------------
%  Team Project – Weekly Report
% --------------------------------------------------------------
\documentclass[12pt]{article}

% ---- Packages --------------------------------------------------
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage[T1]{fontenc}

% ---- Header & Footer -----------------------------------------
\fancyhf{}
\fancyhead[L]{\textit{Distributed Text Editor – Weekly Report}}
\fancyhead[R]{\today}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\pagestyle{fancy}
\setlength{\headheight}{15pt}

% ---- Title ----------------------------------------------
\title{\Huge \textbf{Distributed Text Editor}}
\author{%
  Sławek Brzózka \\
  Julian Konowalski \\
  Jan Zadrąg \\
  Jan Zakroczymski \\
}
\date{\today}

% ---- Weekly counter and macro --------------------------------
\newcounter{week}
\newcommand{\Week}[1]{%
  \stepcounter{week}%
  \section{Week \arabic{week} – #1}\addcontentsline{toc}{section}{Week \arabic{week} – #1}%
  \label{sec:week\arabic{week}}
}

% ---- Document -------------------------------------------------
\begin{document}

\maketitle
\thispagestyle{fancy}
\clearpage

% --------------------------------------------------------------
%  Table of Contents
% --------------------------------------------------------------
\tableofcontents
\clearpage

% --------------------------------------------------------------
%  Weekly Sections
% --------------------------------------------------------------
\Week{Research and design decisions}
\subsection{Problem statement}

Implement concurrent text editing on a LAN network with automatic conflict resolution.

\subsection{Research}

After a preliminary review of the literature, we identified two primary approaches to collaborative 
text editing: \href{https://en.wikipedia.org/wiki/Operational_transformation}{Operational Transformation}(OT) 
and \href{https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type}{Conflict-Free Replicated Data Types}(CRDTs).

Operational Transformation techniques rely on transforming concurrent operations to maintain consistency, 
while CRDTs achieve convergence through mathematically defined merge operations that are inherently 
conflict-free.

Based on our analysis, we concluded that OT could be implemented effectively in \href{https://www.haskell.org/}{Haskell}, 
due to its strong support for functional programming paradigm and immutable data manipulation. Conversely, 
\href{https://www.rust-lang.org}{Rust} and \href{https://isocpp.org/}{C++} are better suited for implementing 
CRDTs because of their expressive and safe type systems, which facilitate the design of efficient and 
reliable data structures.

After careful considerations, we decided to base our implementation on CRDTs, as they are better aligned 
with distributed systems and simpler to maintain in decentralized environments.

\subsection{Technological Stack}

The high susceptibility to errors in distributed systems was one of the main arguments for choosing 
Rust for the application's backend code, considering it's strong and expressive type system. However, 
the most notable disadvantage of this decision was our limited experience with the language.

Another important consideration was the implementation of communication between users. Both of the considered 
languages offer mature networking solutions: \href{https://think-async.com/Asio/}{Asio} for C++ and 
\href{https://tokio.rs/}{Tokio} for Rust. Each met our requirements, and although we had no prior experience 
with Tokio, the available examples presented it as a feature-rich, yet intuitive package.

The next decision concerned the graphical user interface (GUI). In the case of C++, the natural choice 
would have been \href{https://www.qt.io}{Qt}. Its advantage lies in keeping the entire codebase in one 
language. However, Qt doesn't provide enough flexibility to fulfill all of our needs, especially regarding 
multi-cursor editor support. Furthermore, its internal text data structures wouldn't allow for easy 
integration with our custom CRDT model, resulting in data duplication and overcomplication of the codebase.

For these reasons, we decided to go with Rust for the core logic and \href{https://react.dev}{React} 
embedded in an \href{https://www.electronjs.org}{Electron} window for the GUI layer. We experimented 
with two integration approaches: compiling Rust to WebAssembly using \href{https://github.com/drager/wasm-pack}{wasm-pack}, 
and building a C-style shared library to be consumed from \href{https://nodejs.org/en}{Node.js} via 
\href{https://napi.rs/}{napi-rs}. Both approaches presented technical difficulties, but we preliminarily 
chose napi-rs due to its superior performance, disregarding its lower portability at this stage of the 
project.

\subsection{UI Layout Prototype}

We implemented a preliminary version of the GUI consisting of two main components: Taskbar and TextEdit.

The Taskbar handles window controls, providing a draggable area for moving the window around and three 
buttons for minimizing, maximizing, and closing the window. It also manages the main application menus
by providing a basic menu bar. 

The TextEdit component is currently based on a standard editable HTML <div> element, which enables 
direct text editing and user action callbacks. Although this may not be the final solution, it serves 
as a functional prototype for further development.

In addition to these components, we implemented basic keyboard shortcuts. For now they're all connected 
to system alerts and will be integrated with backend functionality at a later stage.

The application has been styled with CSS to achieve a dark and responsive UI theme. TextEdit component's
look has been further enhanced with a custom GLSL fragment shader in order to fine-tune the final presentation
of the product.

All GUI-related code has been written on a dedicated branch (GUI). A pull request has been created, 
peer-reviewed and finally merged into the main branch after resolving the conflicts. We decided to keep 
the dedicated GUI branch for future work, including backend integration and potential adjustments to 
frontend logic.

\Week{Prototyping the core data structure}

\subsection{Sources}

The relative simplicity of implementation and flexibility of Logoot\cite{logoot} structures in terms 
of delete and undo operations led us to adopt this approach. A known disadvantage of this method is 
the rapid growth of index lengths in certain edge cases (inserting at the beggining of the file). This 
problem has been addressed by an improvement known as LSEQ\cite{lseq}, which we will also try to adapt.

\subsection{Index generation}

Due to the fact that the target system is designed to support multi-user editing our structure also 
includes a field containing the peer's ID, as well as a timestamp for resolving conflicts in the future. 
For now both of these values have been set to zero, as we have decided to focus on generating unique 
identifiers. 

We implemented the improved allocation strategy known from LSEQ, but instead of using base doubling 
we have settled for a fixed identifier base equal to \(2^{32}\). We plan to change this in the future
updates.

\subsection{Tree structure}

We used an n-ary tree structure to represent our document, which is natural for our algorithm. Although 
its arity can be very high, it is also expected to be sparsely populated. Therefore, we used a BTreeMap 
to store the children within the vertices of our tree. The key advantage of this approach is it's ability
to be resized without memory reallocations.

Currently, only the insert operation and the pre-order tree traversal have been implemented to compile 
the entire document into a single string. Ultimately, these operations will be based on iterators, but 
the initial goal was to create a minimal working example that verifies the correctness of the ID generation
algorithm.


\Week{Dataset Preparation for Synchronization Testing}

\subsection{Sources}

I learned data mining techniques from \cite{data_mining} to extract and preprocess text data suitable for
testing our distributed text editor's synchronization capabilities. 

\subsection{Purpose}

To evaluate the behavior of our distributed text editor under realistic editing conditions, we required
a dataset that reflects natural language usage instead of artificially generated sequences. The dataset
is intended to support testing of synchronization logic, conflict handling and convergence properties.

\subsection{Data Source Selection}

We chose Wikipedia as the data source due to:
\begin{itemize}
    \item public accessibility and a stable \href{https://pypi.org/project/Wikipedia-API/}{API} for automated retrieval,
    \item sufficiently complex and natural sentence structure,
    \item extensive internal linking, making it easy to gather thematically related material.
\end{itemize}

An initial article is located through a keyword search, and additional articles are collected by following
internal links, resulting in a coherent yet diverse text sample.

\subsection{Text Representation}

The combined article text is transformed into a sequence of elementary editing operations. Each character
is represented as an independent entry, associated with:
\begin{itemize}
    \item its position in the text,
    \item the type of change (insertion or deletion),
    \item a timestamp representing logical operation ordering.
    \item user identity (currently omitted).
\end{itemize}

In curent state of development we focus on single-user editing scenarios, so all operations are assigned
a sequential timestamp. Future iterations will introduce concurrent edits by multiple users.

\subsection{Editing Scenarios}

To test synchronization behavior in different conditions, we prepared several controlled editing scenarios:
\begin{itemize}
    \item \textbf{Gradual text construction:} characters are added sequentially, simulating normal typing.
    \item \textbf{Progressive text removal:} characters are removed step-by-step, simulating revision or rollback.
    \item \textbf{Concurrent modification:} multiple operations share the same timestamp, simulating simultaneous edits.
\end{itemize}

These scenarios help evaluate whether the editor maintains a consistent document state in the presence of
concurrent operations and conflicting modifications. Next scenarios will include more complex patterns for example
test multi-user interactions, and real time collaborative editing.

\subsection{Outcome}

The result is a reproducible dataset based on real text, structured as a sequence of timestamped editing
operations. This dataset will be used in further development to:
\begin{itemize}
    \item assess the correctness of the synchronization algorithm,
    \item evaluate convergence under concurrent editing conditions,
    \item observe system behavior during large-scale modifications.
\end{itemize}




\begin{thebibliography}{9}

\bibitem{logoot}
Weiss, S., Urso, P., \& Molli, P. (2010).
\textit{Logoot-Undo: Distributed Collaborative Editing System on P2P Networks}.
IEEE Transactions on Parallel and Distributed Systems, 21(8), 1162--1174.
\href{https://doi.org/10.1109/TPDS.2009.173}{doi:10.1109/TPDS.2009.173}.

\bibitem{lseq}
Nédelec, B., Molli, P., Mostefaoui, A., \& Desmontils, E. (2013).
\textit{LSEQ: An adaptive structure for sequences in distributed collaborative editing}.
In \textit{Proceedings of the 2013 ACM Symposium on Document Engineering}, 37--46.
\href{https://doi.org/10.1145/2494266.2494278}{doi:10.1145/2494266.2494278}.

\bibitem{data_mining}
Shahbaz Ashraf \textit{Data Mining with Python (Playlist)}.
YouTube, 2023. Available at:
\url{https://www.youtube.com/playlist?list=PLt-uc-DqXJGcBNlYQNV_VYPnaYg80MJK8}



\end{thebibliography}

\end{document}
